{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.getcwd()\n",
    "#import First_Model_Iris.py\n",
    "\n",
    "i = 10 \n",
    "print(i)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import display\n",
    "import IPython\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "\n",
    "\n",
    "[9]\n",
    "#The iris object that is returned by load_iris is a Bunch object,\n",
    "# which is very similar to a dictionary. It contains keys and values:\n",
    "iris_dataset = load_iris()\n",
    "\n",
    "[10]\n",
    "#print(f\"Keys of iris_dataset : {iris_dataset.keys()}\")\n",
    "#The value of the key DESCR is a short description of the dataset.\n",
    "[11]\n",
    "#print(iris_dataset['DESCR'][:193] + \"\\n...\")\n",
    "\n",
    "[12]\n",
    "#The value of the key target_names is an array of strings,\n",
    "# containing the species of flower that we want to predict:\n",
    "#print(iris_dataset['target_names'])\n",
    "\n",
    "[13]\n",
    "#The value of feature_names is a list of strings, giving the description of each feature\n",
    "#print(f\"Features names : \\n {iris_dataset['feature_names']}\")\n",
    "\n",
    "[14]\n",
    "#The data itself is contained in the target and data fields.\n",
    "# data contains the numeric measurements of sepal length, sepal width, petal length, and petal width in a NumPy array\n",
    "#print(f\"type of data : {type(iris_dataset['data'])}\")\n",
    "\n",
    "[15]\n",
    "#print(f\"shape of data : {iris_dataset['data'].shape}\")\n",
    "\n",
    "[16]\n",
    "#print(f\"First Five rows of data : \\n {iris_dataset['data'][:5]}\")\n",
    "#From this data, we can see that all of the first five flowers have a petal width of 0.2 cm\n",
    "# and that the first flower has the longest sepal, at 5.1 cm.\n",
    "\n",
    "[17]\n",
    "#The target array contains the species of each of the flowers that were measured, also as a NumPy array:\n",
    "#print(f\"Type of target : {type(iris_dataset['target'])}\")\n",
    "#target is a one-dimensional array, with one entry per flower\n",
    "\n",
    "[18]\n",
    "#print(f\"shape of target : {iris_dataset['target'].shape}\")\n",
    "#The species are encoded as integers from 0 to 2:\n",
    "\n",
    "[19]\n",
    "#print(f\"Target : \\n {iris_dataset['target']}\")\n",
    "#The meanings of the numbers are given by the iris['target_names'] array: 0 means setosa,\n",
    "# 1 means versicolor, and 2 means virginica.\n",
    "#print(iris_dataset)\n",
    "\n",
    "[20]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(iris_dataset['data'],iris_dataset['target'],random_state=0)\n",
    "\n",
    "#The output of the train_test_split function is X_train, X_test, y_train, and y_test,\n",
    "# which are all NumPy arrays. X_train contains 75% of the rows of the dataset, and X_test contains the remaining 25%:\n",
    "\n",
    "[21]\n",
    "#print(f\"iris data shape : {iris_dataset['data'].shape}\")\n",
    "#print(f\"iris target : { iris_dataset['target'].shape}\")\n",
    "#print(f\"X_train shape : {X_train.shape}\")\n",
    "#print(f\"y_train shape : {y_train.shape}\")\n",
    "\n",
    "[22]\n",
    "#print(f\"X_test shape : {X_test.shape}\")\n",
    "#print(f\"y_test shape : {y_test.shape}\")\n",
    "\n",
    "[23]\n",
    "#create dataframe from data in X_train\n",
    "#label the columns using the strings in iris_dataset.feature_names\n",
    "\n",
    "iris_dataframe = pd.DataFrame(X_train,columns=iris_dataset.feature_names)\n",
    "#print(iris_dataframe)\n",
    "\n",
    "#create a scatter matrix from the dataframe, color byn y_train\n",
    "#pd.plotting.scatter_matrix(iris_dataframe,c=y_train, figsize = (15,15), marker ='o', hist_kwds = {'bins' : 20}, s = 60,alpha =.8, cmap = mglearn.cm3 )\n",
    "#plt.show()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "#To build the model on the training set, we call the fit method of the knn object\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "#print(knn.fit(X_train,y_train))\n",
    "#Making prediction\n",
    "X_new = np.array([[5,2.9,1,0.2]])\n",
    "#print(f\"X_new shape : {X_new.shape}\")\n",
    "i = 10\n",
    "print(i)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
